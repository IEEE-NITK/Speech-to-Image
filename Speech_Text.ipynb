{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sqHMcxIsxVR",
        "outputId": "d55dad21-28f0-4791-e53b-2813f51ac598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-2.5.1-py3-none-any.whl (15 kB)\n",
            "Collecting levenshtein==0.20.2\n",
            "  Downloading Levenshtein-0.20.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<3.0.0,>=2.3.0\n",
            "  Downloading rapidfuzz-2.13.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, levenshtein, jiwer\n",
            "Successfully installed jiwer-2.5.1 levenshtein-0.20.2 rapidfuzz-2.13.7\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "!pip install jiwer\n",
        "import jiwer\n",
        "from jiwer import wer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhZcO0WGsy7w",
        "outputId": "29dcf73a-986a-4d21-d4f4-333a2f3d1af1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
            "2748572632/2748572632 [==============================] - 100s 0us/step\n"
          ]
        }
      ],
      "source": [
        "keras.utils.get_file(\n",
        "    os.path.join(os.getcwd(), \"data.tar.gz\"),\n",
        "    \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\",\n",
        "    extract=True,\n",
        "    archive_format=\"tar\",\n",
        "    cache_dir=\".\",\n",
        ")\n",
        "\n",
        "\n",
        "saveto = \"./datasets/LJSpeech-1.1\"\n",
        "wavs = glob(\"{}/**/*.wav\".format(saveto), recursive=True)\n",
        "\n",
        "id_to_text = {}\n",
        "with open(os.path.join(saveto, \"metadata.csv\"), encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        id = line.strip().split(\"|\")[0]\n",
        "        text = line.strip().split(\"|\")[2]\n",
        "        id_to_text[id] = text\n",
        "\n",
        "\n",
        "def get_data(wavs, id_to_text, maxlen=50):\n",
        "    \"\"\" returns mapping of audio paths and transcription texts \"\"\"\n",
        "    data = []\n",
        "    for w in wavs:\n",
        "        id = w.split(\"/\")[-1].split(\".\")[0]\n",
        "        if len(id_to_text[id]) < maxlen:\n",
        "            data.append({\"audio\": w, \"text\": id_to_text[id]})\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htsvHk2msy-b",
        "outputId": "7457862a-e1b4-4f0b-fb96-7a437e1a75a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ],
      "source": [
        "class VectorizeChar:\n",
        "    def __init__(self, max_len=50):\n",
        "        self.vocab = (\n",
        "            [\"-\", \"#\", \"<\", \">\"]\n",
        "            + [chr(i + 96) for i in range(1, 27)]\n",
        "            + [\" \", \".\", \",\", \"?\"]\n",
        "        )\n",
        "        self.max_len = max_len\n",
        "        self.char_to_idx = {}\n",
        "        for i, ch in enumerate(self.vocab):\n",
        "            self.char_to_idx[ch] = i\n",
        "\n",
        "    def __call__(self, text):\n",
        "        text = text.lower()\n",
        "        text = text[: self.max_len - 2]\n",
        "        text = \"<\" + text + \">\"\n",
        "        pad_len = self.max_len - len(text)\n",
        "        return [self.char_to_idx.get(ch, 1) for ch in text] + [0] * pad_len\n",
        "\n",
        "    def get_vocabulary(self):\n",
        "        return self.vocab\n",
        "\n",
        "\n",
        "max_target_len = 200  # all transcripts in out data are < 200 characters\n",
        "data = get_data(wavs, id_to_text, max_target_len)\n",
        "vectorizer = VectorizeChar(max_target_len)\n",
        "print(\"vocab size\", len(vectorizer.get_vocabulary()))\n",
        "\n",
        "\n",
        "def create_text_ds(data):\n",
        "    texts = [_[\"text\"] for _ in data]\n",
        "    text_ds = [vectorizer(t) for t in texts]\n",
        "    text_ds = tf.data.Dataset.from_tensor_slices(text_ds)\n",
        "    return text_ds\n",
        "\n",
        "\n",
        "def path_to_audio(path):\n",
        "    # spectrogram using stft\n",
        "    audio = tf.io.read_file(path)\n",
        "    audio, _ = tf.audio.decode_wav(audio, 1)\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    stfts = tf.signal.stft(audio, frame_length=200, frame_step=80, fft_length=256)\n",
        "    x = tf.math.pow(tf.abs(stfts), 0.5)\n",
        "    # normalisation\n",
        "    means = tf.math.reduce_mean(x, 1, keepdims=True)\n",
        "    stddevs = tf.math.reduce_std(x, 1, keepdims=True)\n",
        "    x = (x - means) / stddevs\n",
        "    audio_len = tf.shape(x)[0]\n",
        "    # padding to 10 seconds\n",
        "    pad_len = 2754\n",
        "    paddings = tf.constant([[0, pad_len], [0, 0]])\n",
        "    x = tf.pad(x, paddings, \"CONSTANT\")[:pad_len, :]\n",
        "    return x\n",
        "\n",
        "\n",
        "def create_audio_ds(data):\n",
        "    flist = [_[\"audio\"] for _ in data]\n",
        "    audio_ds = tf.data.Dataset.from_tensor_slices(flist)\n",
        "    audio_ds = audio_ds.map(\n",
        "        path_to_audio, num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    return audio_ds\n",
        "\n",
        "\n",
        "def create_tf_dataset(data, bs=4):\n",
        "    audio_ds = create_audio_ds(data)\n",
        "    text_ds = create_text_ds(data)\n",
        "    ds = tf.data.Dataset.zip((audio_ds, text_ds))\n",
        "    ds = ds.map(lambda x, y: {\"source\": x, \"target\": y})\n",
        "    ds = ds.batch(bs)\n",
        "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "\n",
        "split = int(len(data) * 0.99)\n",
        "train_data = data[:split]\n",
        "test_data = data[split:]\n",
        "ds = create_tf_dataset(train_data, bs=64)\n",
        "val_ds = create_tf_dataset(test_data, bs=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TMf5OawQszGs"
      },
      "outputs": [],
      "source": [
        "class DisplayOutputs(keras.callbacks.Callback):\n",
        "    def __init__(\n",
        "        self, batch, idx_to_token, target_start_token_idx=27, target_end_token_idx=28\n",
        "    ):\n",
        "        \"\"\"Displays a batch of outputs after every epoch\n",
        "\n",
        "        Args:\n",
        "            batch: A test batch containing the keys \"source\" and \"target\"\n",
        "            idx_to_token: A List containing the vocabulary tokens corresponding to their indices\n",
        "            target_start_token_idx: A start token index in the target vocabulary\n",
        "            target_end_token_idx: An end token index in the target vocabulary\n",
        "        \"\"\"\n",
        "        self.batch = batch\n",
        "        self.target_start_token_idx = target_start_token_idx\n",
        "        self.target_end_token_idx = target_end_token_idx\n",
        "        self.idx_to_char = idx_to_token\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch % 5 != 0:\n",
        "            return\n",
        "        source = self.batch[\"source\"]\n",
        "        target = self.batch[\"target\"].numpy()\n",
        "        bs = tf.shape(source)[0]\n",
        "        preds = self.model.generate(source, self.target_start_token_idx)\n",
        "        preds = preds.numpy()\n",
        "        for i in range(bs):\n",
        "            target_text = \"\".join([self.idx_to_char[_] for _ in target[i, :]])\n",
        "            prediction = \"\"\n",
        "            for idx in preds[i, :]:\n",
        "                prediction += self.idx_to_char[idx]\n",
        "                if idx == self.target_end_token_idx:\n",
        "                    break\n",
        "            print(f\"target:     {target_text.replace('-','')}\")\n",
        "            print(f\"prediction: {prediction}\\n\")\n",
        "            werscore = wer(target_text, prediction)\n",
        "            print(\"-\" * 100)\n",
        "            print(f\"Word Error Rate: {werscore:.4f}\")\n",
        "            print(\"-\" * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7wYVtIlNszJr"
      },
      "outputs": [],
      "source": [
        "class TokenEmbedding(layers.Layer):\n",
        "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n",
        "        super().__init__()\n",
        "        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        x = self.emb(x)\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        return x + positions\n",
        "\n",
        "\n",
        "class SpeechFeatureEmbedding(layers.Layer):\n",
        "    def __init__(self, num_hid=64, maxlen=100):\n",
        "        super().__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv1D(\n",
        "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
        "        )\n",
        "        self.conv2 = tf.keras.layers.Conv1D(\n",
        "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
        "        )\n",
        "        self.conv3 = tf.keras.layers.Conv1D(\n",
        "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
        "        )\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        return self.conv3(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yv5Qp7wnszMg"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ElPtxQlkszPL"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.self_att = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.self_dropout = layers.Dropout(0.5)\n",
        "        self.enc_dropout = layers.Dropout(0.1)\n",
        "        self.ffn_dropout = layers.Dropout(0.1)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n",
        "        \"\"\"Masks the upper half of the dot product matrix in self attention.\n",
        "\n",
        "        This prevents flow of information from future tokens to current token.\n",
        "        1's in the lower triangle, counting from the lower right corner.\n",
        "        \"\"\"\n",
        "        i = tf.range(n_dest)[:, None]\n",
        "        j = tf.range(n_src)\n",
        "        m = i >= j - n_src + n_dest\n",
        "        mask = tf.cast(m, dtype)\n",
        "        mask = tf.reshape(mask, [1, n_dest, n_src])\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, enc_out, target):\n",
        "        input_shape = tf.shape(target)\n",
        "        batch_size = input_shape[0]\n",
        "        seq_len = input_shape[1]\n",
        "        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
        "        target_att = self.self_att(target, target, attention_mask=causal_mask)\n",
        "        target_norm = self.layernorm1(target + self.self_dropout(target_att))\n",
        "        enc_out = self.enc_att(target_norm, enc_out)\n",
        "        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out) + target_norm)\n",
        "        ffn_out = self.ffn(enc_out_norm)\n",
        "        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out))\n",
        "        return ffn_out_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EmVByydzszSM"
      },
      "outputs": [],
      "source": [
        "class Transformer(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_hid=64,\n",
        "        num_head=2,\n",
        "        num_feed_forward=128,\n",
        "        source_maxlen=100,\n",
        "        target_maxlen=100,\n",
        "        num_layers_enc=4,\n",
        "        num_layers_dec=1,\n",
        "        num_classes=10,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n",
        "        self.num_layers_enc = num_layers_enc\n",
        "        self.num_layers_dec = num_layers_dec\n",
        "        self.target_maxlen = target_maxlen\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.enc_input = SpeechFeatureEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n",
        "        self.dec_input = TokenEmbedding(\n",
        "            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n",
        "        )\n",
        "\n",
        "        self.encoder = keras.Sequential(\n",
        "            [self.enc_input]\n",
        "            + [\n",
        "                TransformerEncoder(num_hid, num_head, num_feed_forward)\n",
        "                for _ in range(num_layers_enc)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        for i in range(num_layers_dec):\n",
        "            setattr(\n",
        "                self,\n",
        "                f\"dec_layer_{i}\",\n",
        "                TransformerDecoder(num_hid, num_head, num_feed_forward),\n",
        "            )\n",
        "\n",
        "        self.classifier = layers.Dense(num_classes)\n",
        "\n",
        "    def decode(self, enc_out, target):\n",
        "        y = self.dec_input(target)\n",
        "        for i in range(self.num_layers_dec):\n",
        "            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y)\n",
        "        return y\n",
        "\n",
        "    def call(self, inputs):\n",
        "        source = inputs[0]\n",
        "        target = inputs[1]\n",
        "        x = self.encoder(source)\n",
        "        y = self.decode(x, target)\n",
        "        return self.classifier(y)\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_metric]\n",
        "\n",
        "    def train_step(self, batch):\n",
        "        \"\"\"Processes one batch inside model.fit().\"\"\"\n",
        "        source = batch[\"source\"]\n",
        "        target = batch[\"target\"]\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        with tf.GradientTape() as tape:\n",
        "            preds = self([source, dec_input])\n",
        "            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "            mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
        "            loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def test_step(self, batch):\n",
        "        source = batch[\"source\"]\n",
        "        target = batch[\"target\"]\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        preds = self([source, dec_input])\n",
        "        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "        mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
        "        loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def generate(self, source, target_start_token_idx):\n",
        "        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n",
        "        bs = tf.shape(source)[0]\n",
        "        enc = self.encoder(source)\n",
        "        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n",
        "        dec_logits = []\n",
        "        for i in range(self.target_maxlen - 1):\n",
        "            dec_out = self.decode(enc, dec_input)\n",
        "            logits = self.classifier(dec_out)\n",
        "            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "            last_logit = tf.expand_dims(logits[:, -1], axis=-1)\n",
        "            dec_logits.append(last_logit)\n",
        "            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n",
        "        return dec_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sFzrfbuLszU4"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        init_lr=0.00001,\n",
        "        lr_after_warmup=0.001,\n",
        "        final_lr=0.00001,\n",
        "        warmup_epochs=15,\n",
        "        decay_epochs=85,\n",
        "        steps_per_epoch=203,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.init_lr = init_lr\n",
        "        self.lr_after_warmup = lr_after_warmup\n",
        "        self.final_lr = final_lr\n",
        "        self.warmup_epochs = warmup_epochs\n",
        "        self.decay_epochs = decay_epochs\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "\n",
        "    def calculate_lr(self, epoch):\n",
        "        \"\"\" linear warm up - linear decay \"\"\"\n",
        "        warmup_lr = (\n",
        "            self.init_lr\n",
        "            + ((self.lr_after_warmup - self.init_lr) / (self.warmup_epochs - 1)) * epoch\n",
        "        )\n",
        "        decay_lr = tf.math.maximum(\n",
        "            self.final_lr,\n",
        "            self.lr_after_warmup\n",
        "            - (epoch - self.warmup_epochs)\n",
        "            * (self.lr_after_warmup - self.final_lr)\n",
        "            / (self.decay_epochs),\n",
        "        )\n",
        "        return tf.math.minimum(warmup_lr, decay_lr)\n",
        "\n",
        "    def __call__(self, step):\n",
        "        epoch = step // self.steps_per_epoch\n",
        "        return self.calculate_lr(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1hptYSwRszXo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f99bf383-4a01-4225-a1ff-20ee95eddfeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "203/203 [==============================] - ETA: 0s - loss: 1.7157target:     <on turning she saw a quizzical look on her husband#s face as he raised his left hand to his throat.>\n",
            "prediction: <the the  o t t ase t t d o t t t the ononee a t t ae t titrs athe the aoe tinthe a the t t t  the t  at there  t  ine  t to the wh oe  t at the at t t t these one thonhe as a   a ine t  see t the    \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 2.8500\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <then he said, #oh, i see,# and that was all.>\n",
            "prediction: <the the  o t t ase t t d o t t t the ononee a t t ae t titrs athe the aoe tinthe a the t t t  the t  at there  t  ine  t to the wh oe  t at the at t t t these one thonhe as a   a ine t  see t the    \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 5.9000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <#four# evidence establishing the ownership of a zipper jacket>\n",
            "prediction: <the the  o t t ase t t d o t t t the ononee a t t ae t titrs athe the aoe tinthe a the t t t  the t  at there  t  ine  t to the wh oe  t at the at t t t these one thonhe as a   a ine t  see t the    \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 6.3333\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <brennan described to the police the man he saw in the window and then identified oswald as the person who most nearly resembled the man he saw.>\n",
            "prediction: <the the  o t t ase t t d o t t t the ononee a t t ae t titrs athe the aoe tinthe a the t t t  the t  at there  t  ine  t to the wh oe  t at the at t t t these one thonhe as a   a ine t  see t the    \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 2.0370\n",
            "----------------------------------------------------------------------------------------------------\n",
            "203/203 [==============================] - 249s 1s/step - loss: 1.7157 - val_loss: 1.5440\n",
            "Epoch 2/60\n",
            "203/203 [==============================] - 203s 997ms/step - loss: 1.4865 - val_loss: 1.4530\n",
            "Epoch 3/60\n",
            "203/203 [==============================] - 197s 969ms/step - loss: 1.4259 - val_loss: 1.4091\n",
            "Epoch 4/60\n",
            "203/203 [==============================] - 197s 967ms/step - loss: 1.3903 - val_loss: 1.3809\n",
            "Epoch 5/60\n",
            "203/203 [==============================] - 194s 953ms/step - loss: 1.3665 - val_loss: 1.3609\n",
            "Epoch 6/60\n",
            "203/203 [==============================] - ETA: 0s - loss: 1.3507target:     <on turning she saw a quizzical look on her husband#s face as he raised his left hand to his throat.>\n",
            "prediction: <the the athe the the the the the the an the as athe the the the the the the the the the the the an the the are the the the ore the on the the the on the the as the as as thes t athe as o athe the t a\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 2.5500\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <then he said, #oh, i see,# and that was all.>\n",
            "prediction: <the the athe the the the the the the an ale an athe the the the the the the the the an the the the the of are the the wan ore ware on athere are t the the te ale there than an the the the the the t a\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 5.1000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <#four# evidence establishing the ownership of a zipper jacket>\n",
            "prediction: <the the athe the the the the the the an the as athe the the the the the the the the the the the an the of an the the the the the the the an there on the the ale one on theres t athe athe athe the t a\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 5.4444\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <brennan described to the police the man he saw in the window and then identified oswald as the person who most nearly resembled the man he saw.>\n",
            "prediction: <the the athe the the the the the the an the an athe the the the the the the the the an the t the an the the the the an an ore an the the an there on the the as the ate ther an the the an athe the t a\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.7778\n",
            "----------------------------------------------------------------------------------------------------\n",
            "203/203 [==============================] - 201s 989ms/step - loss: 1.3507 - val_loss: 1.3485\n",
            "Epoch 7/60\n",
            "203/203 [==============================] - 191s 939ms/step - loss: 1.3402 - val_loss: 1.3401\n",
            "Epoch 8/60\n",
            "203/203 [==============================] - 192s 943ms/step - loss: 1.3327 - val_loss: 1.3340\n",
            "Epoch 9/60\n",
            "203/203 [==============================] - 194s 950ms/step - loss: 1.3271 - val_loss: 1.3292\n",
            "Epoch 10/60\n",
            "203/203 [==============================] - 198s 976ms/step - loss: 1.3227 - val_loss: 1.3255\n",
            "Epoch 11/60\n",
            "203/203 [==============================] - ETA: 0s - loss: 1.3191target:     <on turning she saw a quizzical look on her husband#s face as he raised his left hand to his throat.>\n",
            "prediction: <the the the the the the the the the the as the as as the the as the the the the the the the the as the the as the the the ore the the the the the ofof theres.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.9500\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <then he said, #oh, i see,# and that was all.>\n",
            "prediction: <the as the the the athe the the an the the the are the the the the an the the the the the the are the the are the the wan.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 3.1000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <#four# evidence establishing the ownership of a zipper jacket>\n",
            "prediction: <the the the the the the the the an the the the are the the the the the the the the the the the the the the are the the the the the orere are the the therere ale on>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 4.3333\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <brennan described to the police the man he saw in the window and then identified oswald as the person who most nearly resembled the man he saw.>\n",
            "prediction: <the as the the the athe the the an the the the are the the the the the the an the the the the are the the an the the the the the the the are the the the ane ale on are theron the ine the athe the t a\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.7037\n",
            "----------------------------------------------------------------------------------------------------\n",
            "203/203 [==============================] - 208s 1s/step - loss: 1.3191 - val_loss: 1.3225\n",
            "Epoch 12/60\n",
            "203/203 [==============================] - 197s 966ms/step - loss: 1.3162 - val_loss: 1.3200\n",
            "Epoch 13/60\n",
            "203/203 [==============================] - 196s 963ms/step - loss: 1.3136 - val_loss: 1.3178\n",
            "Epoch 14/60\n",
            "203/203 [==============================] - 203s 998ms/step - loss: 1.3114 - val_loss: 1.3157\n",
            "Epoch 15/60\n",
            "203/203 [==============================] - 193s 948ms/step - loss: 1.3094 - val_loss: 1.3138\n",
            "Epoch 16/60\n",
            "203/203 [==============================] - ETA: 0s - loss: 1.3076target:     <on turning she saw a quizzical look on her husband#s face as he raised his left hand to his throat.>\n",
            "prediction: <the the the s as the as ofore the the the the the the as the the the the the the the the the the as the the the the the as.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.5500\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <then he said, #oh, i see,# and that was all.>\n",
            "prediction: <the as the athe the the the the an the the the athe the the the the ale the an the ale the the the the the.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 2.7000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <#four# evidence establishing the ownership of a zipper jacket>\n",
            "prediction: <the the the the the the the the the the the the the the the the the the the the the the the the the there the the there the there.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 3.3333\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <brennan described to the police the man he saw in the window and then identified oswald as the person who most nearly resembled the man he saw.>\n",
            "prediction: <the as the ale the ale the the the the the the an an the the the ale the the the the athe the an an the the an the the the the the on the the the ofof the athe the are thenthe the the an allas t t t \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.7037\n",
            "----------------------------------------------------------------------------------------------------\n",
            "203/203 [==============================] - 199s 980ms/step - loss: 1.3076 - val_loss: 1.3123\n",
            "Epoch 17/60\n",
            "203/203 [==============================] - 191s 937ms/step - loss: 1.3060 - val_loss: 1.3109\n",
            "Epoch 18/60\n",
            "203/203 [==============================] - 187s 921ms/step - loss: 1.3046 - val_loss: 1.3096\n",
            "Epoch 19/60\n",
            "203/203 [==============================] - 187s 918ms/step - loss: 1.3033 - val_loss: 1.3085\n",
            "Epoch 20/60\n",
            "203/203 [==============================] - 186s 915ms/step - loss: 1.3020 - val_loss: 1.3074\n",
            "Epoch 21/60\n",
            "203/203 [==============================] - ETA: 0s - loss: 1.3008target:     <on turning she saw a quizzical look on her husband#s face as he raised his left hand to his throat.>\n",
            "prediction: <the se the ofore the the the the the the s the the the the the the s the the the ore the the the s the s the the the the orere therererereres.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.7000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <then he said, #oh, i see,# and that was all.>\n",
            "prediction: <the as the athe the the the an an an an an the as and ale the the the the an.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 2.0000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <#four# evidence establishing the ownership of a zipper jacket>\n",
            "prediction: <the the the the the the the the the the the the the the the the the the the the the the the the the there the the there.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 3.1111\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <brennan described to the police the man he saw in the window and then identified oswald as the person who most nearly resembled the man he saw.>\n",
            "prediction: <the as the ale the ale the the the the the the as an the the the ale the the the ale the the the an the the an the the the the the ale the the the an ale and ale there thenthe thed the one be walin a\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.6667\n",
            "----------------------------------------------------------------------------------------------------\n",
            "203/203 [==============================] - 192s 946ms/step - loss: 1.3008 - val_loss: 1.3064\n",
            "Epoch 22/60\n",
            "203/203 [==============================] - 187s 918ms/step - loss: 1.2996 - val_loss: 1.3054\n",
            "Epoch 23/60\n",
            "203/203 [==============================] - 187s 917ms/step - loss: 1.2985 - val_loss: 1.3045\n",
            "Epoch 24/60\n",
            "203/203 [==============================] - 187s 917ms/step - loss: 1.2974 - val_loss: 1.3037\n",
            "Epoch 25/60\n",
            "203/203 [==============================] - 186s 917ms/step - loss: 1.2963 - val_loss: 1.3029\n",
            "Epoch 26/60\n",
            "203/203 [==============================] - ETA: 0s - loss: 1.2953target:     <on turning she saw a quizzical look on her husband#s face as he raised his left hand to his throat.>\n",
            "prediction: <the se the sere the the s ore the the the the the s as as ofore the the the the the the s the ore the the as the the the the the thererereres.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.7000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <then he said, #oh, i see,# and that was all.>\n",
            "prediction: <the as ale and the ale the the an an an an ale and the the.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.6000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <#four# evidence establishing the ownership of a zipper jacket>\n",
            "prediction: <the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 3.2222\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <brennan described to the police the man he saw in the window and then identified oswald as the person who most nearly resembled the man he saw.>\n",
            "prediction: <the as the an the the the the the an an as the as an the the ale an the an the the an the the an an the the an an the an the the the the the the the the ane alle there asenthe thedere an allan t t t \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.7407\n",
            "----------------------------------------------------------------------------------------------------\n",
            "203/203 [==============================] - 193s 949ms/step - loss: 1.2953 - val_loss: 1.3020\n",
            "Epoch 27/60\n",
            "203/203 [==============================] - 191s 938ms/step - loss: 1.2943 - val_loss: 1.3012\n",
            "Epoch 28/60\n",
            "203/203 [==============================] - 191s 941ms/step - loss: 1.2934 - val_loss: 1.3004\n",
            "Epoch 29/60\n",
            "203/203 [==============================] - 190s 934ms/step - loss: 1.2924 - val_loss: 1.2997\n",
            "Epoch 30/60\n",
            "203/203 [==============================] - 191s 937ms/step - loss: 1.2915 - val_loss: 1.2989\n",
            "Epoch 31/60\n",
            "203/203 [==============================] - ETA: 0s - loss: 1.2906target:     <on turning she saw a quizzical look on her husband#s face as he raised his left hand to his throat.>\n",
            "prediction: <the se the sere the s athe s are the sere the the s ase the as the the the s ore the the ore the s s s ofore the the therererere thererere.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.6500\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <then he said, #oh, i see,# and that was all.>\n",
            "prediction: <and the the as ale ale the the an an an an ase and.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.4000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <#four# evidence establishing the ownership of a zipper jacket>\n",
            "prediction: <the as the the the athe the the the the as the the the the the the the the the the athe the the as the the the the the.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 3.2222\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <brennan described to the police the man he saw in the window and then identified oswald as the person who most nearly resembled the man he saw.>\n",
            "prediction: <the se the an the s an ale the the the s an an an and an the s the an the an the an the an on an an the the an an the an the the the the the the the ane ane alle there wand watheedy.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.6296\n",
            "----------------------------------------------------------------------------------------------------\n",
            "203/203 [==============================] - 191s 939ms/step - loss: 1.2906 - val_loss: 1.2981\n",
            "Epoch 32/60\n",
            "203/203 [==============================] - 187s 921ms/step - loss: 1.2898 - val_loss: 1.2974\n",
            "Epoch 33/60\n",
            "203/203 [==============================] - 189s 931ms/step - loss: 1.2889 - val_loss: 1.2967\n",
            "Epoch 34/60\n",
            "203/203 [==============================] - 190s 935ms/step - loss: 1.2880 - val_loss: 1.2959\n",
            "Epoch 35/60\n",
            "203/203 [==============================] - 190s 932ms/step - loss: 1.2871 - val_loss: 1.2951\n",
            "Epoch 36/60\n",
            "203/203 [==============================] - ETA: 0s - loss: 1.2861target:     <on turning she saw a quizzical look on her husband#s face as he raised his left hand to his throat.>\n",
            "prediction: <the se sere anthe s sere the the sere sere the s an an are the sofofon the s the se the s the serere s there the the therererere s.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.5500\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <then he said, #oh, i see,# and that was all.>\n",
            "prediction: <and the the s ale an as an and and and aned alan.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.2000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <#four# evidence establishing the ownership of a zipper jacket>\n",
            "prediction: <the as the an an the the ofof the the the the the as as the as the an the are the of the are the anthe.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 2.7778\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <brennan described to the police the man he saw in the window and then identified oswald as the person who most nearly resembled the man he saw.>\n",
            "prediction: <the se the s anofon the s the the the the s an an s an an an s the an the an ore an the an on an an the the the the the the the the s the an s the on ale ane the there wand watheedy.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.6667\n",
            "----------------------------------------------------------------------------------------------------\n",
            "203/203 [==============================] - 193s 947ms/step - loss: 1.2861 - val_loss: 1.2942\n",
            "Epoch 37/60\n",
            "203/203 [==============================] - 187s 918ms/step - loss: 1.2851 - val_loss: 1.2931\n",
            "Epoch 38/60\n",
            "203/203 [==============================] - 186s 913ms/step - loss: 1.2839 - val_loss: 1.2919\n",
            "Epoch 39/60\n",
            "203/203 [==============================] - 185s 908ms/step - loss: 1.2827 - val_loss: 1.2907\n",
            "Epoch 40/60\n",
            "203/203 [==============================] - 185s 908ms/step - loss: 1.2814 - val_loss: 1.2895\n",
            "Epoch 41/60\n",
            "203/203 [==============================] - ETA: 0s - loss: 1.2800target:     <on turning she saw a quizzical look on her husband#s face as he raised his left hand to his throat.>\n",
            "prediction: <and sore sthe the se sere the the sere se se anofore the s the the s the the ore se the s sere arere s se arere the there serere.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.5500\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <then he said, #oh, i see,# and that was all.>\n",
            "prediction: <and se the an ale se and and and athe and.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.0000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <#four# evidence establishing the ownership of a zipper jacket>\n",
            "prediction: <and the the as as athe the the an the an of as an an and the an and of the are the ande anthe.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 2.5556\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <brennan described to the police the man he saw in the window and then identified oswald as the person who most nearly resembled the man he saw.>\n",
            "prediction: <the se the s wane the the s an the an s anore s anofon the the the s the an the the the s s an an s anore an an an the the the s an the the the the s alofore the there wand watheedy.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.5926\n",
            "----------------------------------------------------------------------------------------------------\n",
            "203/203 [==============================] - 191s 940ms/step - loss: 1.2800 - val_loss: 1.2884\n",
            "Epoch 42/60\n",
            "203/203 [==============================] - 186s 915ms/step - loss: 1.2787 - val_loss: 1.2872\n",
            "Epoch 43/60\n",
            "203/203 [==============================] - 186s 915ms/step - loss: 1.2774 - val_loss: 1.2861\n",
            "Epoch 44/60\n",
            "203/203 [==============================] - 186s 915ms/step - loss: 1.2761 - val_loss: 1.2851\n",
            "Epoch 45/60\n",
            "203/203 [==============================] - 187s 918ms/step - loss: 1.2749 - val_loss: 1.2841\n",
            "Epoch 46/60\n",
            "203/203 [==============================] - ETA: 0s - loss: 1.2737target:     <on turning she saw a quizzical look on her husband#s face as he raised his left hand to his throat.>\n",
            "prediction: <on sere the sere the s se arere the se se sofofof the are the s an s the the ore se the s serererere se the sere thereanthe.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.4000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <then he said, #oh, i see,# and that was all.>\n",
            "prediction: <and se the an as ane and se ande athe sean.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.0000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <#four# evidence establishing the ownership of a zipper jacket>\n",
            "prediction: <and the as and and athe the an an the as of are and as are and the and and ande.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 2.1111\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <brennan described to the police the man he saw in the window and then identified oswald as the person who most nearly resembled the man he saw.>\n",
            "prediction: <mas the the s ane the the s anore s anon the an the s an the s the an the an ore an the s s ofofof an the an the the the an the s ofon s alore the ond and and the thererdenthe ssedy.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.5556\n",
            "----------------------------------------------------------------------------------------------------\n",
            "203/203 [==============================] - 190s 937ms/step - loss: 1.2737 - val_loss: 1.2832\n",
            "Epoch 47/60\n",
            "203/203 [==============================] - 185s 910ms/step - loss: 1.2726 - val_loss: 1.2823\n",
            "Epoch 48/60\n",
            "203/203 [==============================] - 185s 911ms/step - loss: 1.2716 - val_loss: 1.2814\n",
            "Epoch 49/60\n",
            "203/203 [==============================] - 186s 913ms/step - loss: 1.2705 - val_loss: 1.2806\n",
            "Epoch 50/60\n",
            "203/203 [==============================] - 185s 909ms/step - loss: 1.2695 - val_loss: 1.2797\n",
            "Epoch 51/60\n",
            "203/203 [==============================] - ETA: 0s - loss: 1.2685target:     <on turning she saw a quizzical look on her husband#s face as he raised his left hand to his throat.>\n",
            "prediction: <on sere the sere the s se are se there se sthe ofofore the s s the se the are se are the se ofofof s serere the the thenthe the.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.5000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <then he said, #oh, i see,# and that was all.>\n",
            "prediction: <and se the sean an aland se aland the as.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.0000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <#four# evidence establishing the ownership of a zipper jacket>\n",
            "prediction: <and as the an an the anof the he as as and are and and are and the and and ande.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 2.2222\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <brennan described to the police the man he saw in the window and then identified oswald as the person who most nearly resembled the man he saw.>\n",
            "prediction: <mas the the s anon an the the s ane the s s anore the an the s the anore the the an the s s ofof an ofore the s an the the the s s aloure and the an ane se on the thererdentheennedy.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.5185\n",
            "----------------------------------------------------------------------------------------------------\n",
            "203/203 [==============================] - 189s 929ms/step - loss: 1.2685 - val_loss: 1.2789\n",
            "Epoch 52/60\n",
            "203/203 [==============================] - 185s 909ms/step - loss: 1.2676 - val_loss: 1.2782\n",
            "Epoch 53/60\n",
            "203/203 [==============================] - 185s 908ms/step - loss: 1.2666 - val_loss: 1.2775\n",
            "Epoch 54/60\n",
            "203/203 [==============================] - 184s 902ms/step - loss: 1.2657 - val_loss: 1.2768\n",
            "Epoch 55/60\n",
            "203/203 [==============================] - 179s 880ms/step - loss: 1.2648 - val_loss: 1.2761\n",
            "Epoch 56/60\n",
            "203/203 [==============================] - ETA: 0s - loss: 1.2639target:     <on turning she saw a quizzical look on her husband#s face as he raised his left hand to his throat.>\n",
            "prediction: <on sere the se sthe ore se sthe anof the s are s are se the se the s the ore ore se sofofore the s se the there the seanthe.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.5000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <then he said, #oh, i see,# and that was all.>\n",
            "prediction: <and the se sean athe s alalland and as.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.0000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <#four# evidence establishing the ownership of a zipper jacket>\n",
            "prediction: <and as the and and as anof the and and are are and and the ashe and and ande as.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 2.1111\n",
            "----------------------------------------------------------------------------------------------------\n",
            "target:     <brennan described to the police the man he saw in the window and then identified oswald as the person who most nearly resembled the man he saw.>\n",
            "prediction: <mren the sson the an the ore the the the s as an an the the an the s the ane ous an the s the an of ofoure the s the the the the s as an an the the ofoure and the the sthentheennedy.>\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.5185\n",
            "----------------------------------------------------------------------------------------------------\n",
            "203/203 [==============================] - 186s 915ms/step - loss: 1.2639 - val_loss: 1.2755\n",
            "Epoch 57/60\n",
            "203/203 [==============================] - 180s 885ms/step - loss: 1.2630 - val_loss: 1.2748\n",
            "Epoch 58/60\n",
            "203/203 [==============================] - 180s 884ms/step - loss: 1.2621 - val_loss: 1.2742\n",
            "Epoch 59/60\n",
            "203/203 [==============================] - 183s 896ms/step - loss: 1.2612 - val_loss: 1.2735\n",
            "Epoch 60/60\n",
            "203/203 [==============================] - 180s 886ms/step - loss: 1.2604 - val_loss: 1.2729\n"
          ]
        }
      ],
      "source": [
        "batch = next(iter(val_ds))\n",
        "\n",
        "# The vocabulary to convert predicted indices into characters\n",
        "idx_to_char = vectorizer.get_vocabulary()\n",
        "display_cb = DisplayOutputs(\n",
        "    batch, idx_to_char, target_start_token_idx=2, target_end_token_idx=3\n",
        ")  # set the arguments as per vocabulary index for '<' and '>'\n",
        "\n",
        "model = Transformer(\n",
        "    num_hid=200,\n",
        "    num_head=2,\n",
        "    num_feed_forward=400,\n",
        "    target_maxlen=max_target_len,\n",
        "    num_layers_enc=4,\n",
        "    num_layers_dec=1,\n",
        "    num_classes=34,\n",
        ")\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(\n",
        "    from_logits=True, label_smoothing=0.1,\n",
        ")\n",
        "\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.00001,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9)\n",
        "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "model.compile(optimizer=optimizer, loss=loss_fn)\n",
        "\n",
        "history = model.fit(ds, validation_data=val_ds, callbacks=[display_cb], epochs=60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5yI23lUHUtDe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f4e547-f38f-493d-d196-6202cef9dda0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.embedding.Embedding object at 0x7f574d0991f0>, because it is not built.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla, conv1d_layer_call_fn, conv1d_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv1d_1_layer_call_fn while saving (showing 5 of 142). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "model.save('Saved_model.pb')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(\"/content/Audio (2).mp3\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "CBLybqoOpytD",
        "outputId": "eae564e4-93cd-4a1d-ba31-e45b4d1bf9a9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-447dbb4fa390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/Audio (2).mp3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    904\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2_behavior\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "PO2L9tVRv3C1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gY4S83rGGrXe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}