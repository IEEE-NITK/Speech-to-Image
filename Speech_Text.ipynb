{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wfeEeHdzVjg0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.get_file(\n",
        "    os.path.join(os.getcwd(), \"data.tar.gz\"),\n",
        "    \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\",\n",
        "    extract=True,\n",
        "    archive_format=\"tar\",\n",
        "    cache_dir=\".\",\n",
        ")\n",
        "\n",
        "\n",
        "saveto = \"./datasets/LJSpeech-1.1\"\n",
        "wavs = glob(\"{}/**/*.wav\".format(saveto), recursive=True)\n",
        "\n",
        "id_to_text = {}\n",
        "with open(os.path.join(saveto, \"metadata.csv\"), encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        id = line.strip().split(\"|\")[0]\n",
        "        text = line.strip().split(\"|\")[2]\n",
        "        id_to_text[id] = text\n",
        "\n",
        "\n",
        "def get_data(wavs, id_to_text, maxlen=50):\n",
        "    \"\"\" returns mapping of audio paths and transcription texts \"\"\"\n",
        "    data = []\n",
        "    for w in wavs:\n",
        "        id = w.split(\"/\")[-1].split(\".\")[0]\n",
        "        if len(id_to_text[id]) < maxlen:\n",
        "            data.append({\"audio\": w, \"text\": id_to_text[id]})\n",
        "    return data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlKiYuD7Vq44",
        "outputId": "d9a5e6e0-f47e-4d13-ce60-02ad66487c4c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
            "2748572632/2748572632 [==============================] - 75s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VectorizeChar:\n",
        "    def __init__(self, max_len=50):\n",
        "        self.vocab = (\n",
        "            [\"-\", \"#\", \"<\", \">\"]\n",
        "            + [chr(i + 96) for i in range(1, 27)]\n",
        "            + [\" \", \".\", \",\", \"?\"]\n",
        "        )\n",
        "        self.max_len = max_len\n",
        "        self.char_to_idx = {}\n",
        "        for i, ch in enumerate(self.vocab):\n",
        "            self.char_to_idx[ch] = i\n",
        "\n",
        "    def __call__(self, text):\n",
        "        text = text.lower()\n",
        "        text = text[: self.max_len - 2]\n",
        "        text = \"<\" + text + \">\"\n",
        "        pad_len = self.max_len - len(text)\n",
        "        return [self.char_to_idx.get(ch, 1) for ch in text] + [0] * pad_len\n",
        "\n",
        "    def get_vocabulary(self):\n",
        "        return self.vocab\n",
        "\n",
        "\n",
        "max_target_len = 200  # all transcripts in out data are < 200 characters\n",
        "data = get_data(wavs, id_to_text, max_target_len)\n",
        "vectorizer = VectorizeChar(max_target_len)\n",
        "print(\"vocab size\", len(vectorizer.get_vocabulary()))\n",
        "\n",
        "\n",
        "def create_text_ds(data):\n",
        "    texts = [_[\"text\"] for _ in data]\n",
        "    text_ds = [vectorizer(t) for t in texts]\n",
        "    text_ds = tf.data.Dataset.from_tensor_slices(text_ds)\n",
        "    return text_ds\n",
        "\n",
        "\n",
        "def path_to_audio(path):\n",
        "    # spectrogram using stft\n",
        "    audio = tf.io.read_file(path)\n",
        "    audio, _ = tf.audio.decode_wav(audio, 1)\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    stfts = tf.signal.stft(audio, frame_length=200, frame_step=80, fft_length=256)\n",
        "    x = tf.math.pow(tf.abs(stfts), 0.5)\n",
        "    # normalisation\n",
        "    means = tf.math.reduce_mean(x, 1, keepdims=True)\n",
        "    stddevs = tf.math.reduce_std(x, 1, keepdims=True)\n",
        "    x = (x - means) / stddevs\n",
        "    audio_len = tf.shape(x)[0]\n",
        "    # padding to 10 seconds\n",
        "    pad_len = 2754\n",
        "    paddings = tf.constant([[0, pad_len], [0, 0]])\n",
        "    x = tf.pad(x, paddings, \"CONSTANT\")[:pad_len, :]\n",
        "    return x\n",
        "\n",
        "\n",
        "def create_audio_ds(data):\n",
        "    flist = [_[\"audio\"] for _ in data]\n",
        "    audio_ds = tf.data.Dataset.from_tensor_slices(flist)\n",
        "    audio_ds = audio_ds.map(\n",
        "        path_to_audio, num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    return audio_ds\n",
        "\n",
        "\n",
        "def create_tf_dataset(data, bs=4):\n",
        "    audio_ds = create_audio_ds(data)\n",
        "    text_ds = create_text_ds(data)\n",
        "    ds = tf.data.Dataset.zip((audio_ds, text_ds))\n",
        "    ds = ds.map(lambda x, y: {\"source\": x, \"target\": y})\n",
        "    ds = ds.batch(bs)\n",
        "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "\n",
        "split = int(len(data) * 0.99)\n",
        "train_data = data[:split]\n",
        "test_data = data[split:]\n",
        "ds = create_tf_dataset(train_data, bs=64)\n",
        "val_ds = create_tf_dataset(test_data, bs=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXGZh3tpVw6T",
        "outputId": "e7e34863-9323-4497-eafc-60a9a0a7775d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size 34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DisplayOutputs(keras.callbacks.Callback):\n",
        "    def __init__(\n",
        "        self, batch, idx_to_token, target_start_token_idx=27, target_end_token_idx=28\n",
        "    ):\n",
        "        \"\"\"Displays a batch of outputs after every epoch\n",
        "\n",
        "        Args:\n",
        "            batch: A test batch containing the keys \"source\" and \"target\"\n",
        "            idx_to_token: A List containing the vocabulary tokens corresponding to their indices\n",
        "            target_start_token_idx: A start token index in the target vocabulary\n",
        "            target_end_token_idx: An end token index in the target vocabulary\n",
        "        \"\"\"\n",
        "        self.batch = batch\n",
        "        self.target_start_token_idx = target_start_token_idx\n",
        "        self.target_end_token_idx = target_end_token_idx\n",
        "        self.idx_to_char = idx_to_token\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch % 5 != 0:\n",
        "            return\n",
        "        source = self.batch[\"source\"]\n",
        "        target = self.batch[\"target\"].numpy()\n",
        "        bs = tf.shape(source)[0]\n",
        "        preds = self.model.generate(source, self.target_start_token_idx)\n",
        "        preds = preds.numpy()\n",
        "        for i in range(bs):\n",
        "            target_text = \"\".join([self.idx_to_char[_] for _ in target[i, :]])\n",
        "            prediction = \"\"\n",
        "            for idx in preds[i, :]:\n",
        "                prediction += self.idx_to_char[idx]\n",
        "                if idx == self.target_end_token_idx:\n",
        "                    break\n",
        "            print(f\"target:     {target_text.replace('-','')}\")\n",
        "            print(f\"prediction: {prediction}\\n\")"
      ],
      "metadata": {
        "id": "Q17NyAwgWS21"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenEmbedding(layers.Layer):\n",
        "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n",
        "        super().__init__()\n",
        "        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        x = self.emb(x)\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        return x + positions\n",
        "\n",
        "\n",
        "class SpeechFeatureEmbedding(layers.Layer):\n",
        "    def __init__(self, num_hid=64, maxlen=100):\n",
        "        super().__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv1D(\n",
        "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
        "        )\n",
        "        self.conv2 = tf.keras.layers.Conv1D(\n",
        "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
        "        )\n",
        "        self.conv3 = tf.keras.layers.Conv1D(\n",
        "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
        "        )\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        return self.conv3(x)"
      ],
      "metadata": {
        "id": "wxiNW59AWhks"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "metadata": {
        "id": "x8B-iOT5WhqO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.self_att = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.self_dropout = layers.Dropout(0.5)\n",
        "        self.enc_dropout = layers.Dropout(0.1)\n",
        "        self.ffn_dropout = layers.Dropout(0.1)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n",
        "        \"\"\"Masks the upper half of the dot product matrix in self attention.\n",
        "\n",
        "        This prevents flow of information from future tokens to current token.\n",
        "        1's in the lower triangle, counting from the lower right corner.\n",
        "        \"\"\"\n",
        "        i = tf.range(n_dest)[:, None]\n",
        "        j = tf.range(n_src)\n",
        "        m = i >= j - n_src + n_dest\n",
        "        mask = tf.cast(m, dtype)\n",
        "        mask = tf.reshape(mask, [1, n_dest, n_src])\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, enc_out, target):\n",
        "        input_shape = tf.shape(target)\n",
        "        batch_size = input_shape[0]\n",
        "        seq_len = input_shape[1]\n",
        "        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
        "        target_att = self.self_att(target, target, attention_mask=causal_mask)\n",
        "        target_norm = self.layernorm1(target + self.self_dropout(target_att))\n",
        "        enc_out = self.enc_att(target_norm, enc_out)\n",
        "        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out) + target_norm)\n",
        "        ffn_out = self.ffn(enc_out_norm)\n",
        "        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out))\n",
        "        return ffn_out_norm"
      ],
      "metadata": {
        "id": "Y4tGETAsWhtM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_hid=64,\n",
        "        num_head=2,\n",
        "        num_feed_forward=128,\n",
        "        source_maxlen=100,\n",
        "        target_maxlen=100,\n",
        "        num_layers_enc=4,\n",
        "        num_layers_dec=1,\n",
        "        num_classes=10,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n",
        "        self.num_layers_enc = num_layers_enc\n",
        "        self.num_layers_dec = num_layers_dec\n",
        "        self.target_maxlen = target_maxlen\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.enc_input = SpeechFeatureEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n",
        "        self.dec_input = TokenEmbedding(\n",
        "            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n",
        "        )\n",
        "\n",
        "        self.encoder = keras.Sequential(\n",
        "            [self.enc_input]\n",
        "            + [\n",
        "                TransformerEncoder(num_hid, num_head, num_feed_forward)\n",
        "                for _ in range(num_layers_enc)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        for i in range(num_layers_dec):\n",
        "            setattr(\n",
        "                self,\n",
        "                f\"dec_layer_{i}\",\n",
        "                TransformerDecoder(num_hid, num_head, num_feed_forward),\n",
        "            )\n",
        "\n",
        "        self.classifier = layers.Dense(num_classes)\n",
        "\n",
        "    def decode(self, enc_out, target):\n",
        "        y = self.dec_input(target)\n",
        "        for i in range(self.num_layers_dec):\n",
        "            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y)\n",
        "        return y\n",
        "\n",
        "    def call(self, inputs):\n",
        "        source = inputs[0]\n",
        "        target = inputs[1]\n",
        "        x = self.encoder(source)\n",
        "        y = self.decode(x, target)\n",
        "        return self.classifier(y)\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_metric]\n",
        "\n",
        "    def train_step(self, batch):\n",
        "        \"\"\"Processes one batch inside model.fit().\"\"\"\n",
        "        source = batch[\"source\"]\n",
        "        target = batch[\"target\"]\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        with tf.GradientTape() as tape:\n",
        "            preds = self([source, dec_input])\n",
        "            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "            mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
        "            loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def test_step(self, batch):\n",
        "        source = batch[\"source\"]\n",
        "        target = batch[\"target\"]\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        preds = self([source, dec_input])\n",
        "        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "        mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
        "        loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def generate(self, source, target_start_token_idx):\n",
        "        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n",
        "        bs = tf.shape(source)[0]\n",
        "        enc = self.encoder(source)\n",
        "        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n",
        "        dec_logits = []\n",
        "        for i in range(self.target_maxlen - 1):\n",
        "            dec_out = self.decode(enc, dec_input)\n",
        "            logits = self.classifier(dec_out)\n",
        "            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "            last_logit = tf.expand_dims(logits[:, -1], axis=-1)\n",
        "            dec_logits.append(last_logit)\n",
        "            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n",
        "        return dec_input"
      ],
      "metadata": {
        "id": "7AXZvqT3Whvm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        init_lr=0.00001,\n",
        "        lr_after_warmup=0.001,\n",
        "        final_lr=0.00001,\n",
        "        warmup_epochs=15,\n",
        "        decay_epochs=85,\n",
        "        steps_per_epoch=203,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.init_lr = init_lr\n",
        "        self.lr_after_warmup = lr_after_warmup\n",
        "        self.final_lr = final_lr\n",
        "        self.warmup_epochs = warmup_epochs\n",
        "        self.decay_epochs = decay_epochs\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "\n",
        "    def calculate_lr(self, epoch):\n",
        "        \"\"\" linear warm up - linear decay \"\"\"\n",
        "        warmup_lr = (\n",
        "            self.init_lr\n",
        "            + ((self.lr_after_warmup - self.init_lr) / (self.warmup_epochs - 1)) * epoch\n",
        "        )\n",
        "        decay_lr = tf.math.maximum(\n",
        "            self.final_lr,\n",
        "            self.lr_after_warmup\n",
        "            - (epoch - self.warmup_epochs)\n",
        "            * (self.lr_after_warmup - self.final_lr)\n",
        "            / (self.decay_epochs),\n",
        "        )\n",
        "        return tf.math.minimum(warmup_lr, decay_lr)\n",
        "\n",
        "    def __call__(self, step):\n",
        "        epoch = step // self.steps_per_epoch\n",
        "        return self.calculate_lr(epoch)"
      ],
      "metadata": {
        "id": "iRgXOMeNWhyU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(val_ds))\n",
        "\n",
        "# The vocabulary to convert predicted indices into characters\n",
        "idx_to_char = vectorizer.get_vocabulary()\n",
        "display_cb = DisplayOutputs(\n",
        "    batch, idx_to_char, target_start_token_idx=2, target_end_token_idx=3\n",
        ")  # set the arguments as per vocabulary index for '<' and '>'\n",
        "\n",
        "model = Transformer(\n",
        "    num_hid=200,\n",
        "    num_head=2,\n",
        "    num_feed_forward=400,\n",
        "    target_maxlen=max_target_len,\n",
        "    num_layers_enc=4,\n",
        "    num_layers_dec=1,\n",
        "    num_classes=34,\n",
        ")\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(\n",
        "    from_logits=True, label_smoothing=0.1,\n",
        ")\n",
        "\n",
        "learning_rate = CustomSchedule(\n",
        "    init_lr=0.00001,\n",
        "    lr_after_warmup=0.001,\n",
        "    final_lr=0.00001,\n",
        "    warmup_epochs=15,\n",
        "    decay_epochs=85,\n",
        "    steps_per_epoch=len(ds),\n",
        ")\n",
        "optimizer = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer=optimizer, loss=loss_fn)\n",
        "\n",
        "history = model.fit(ds, validation_data=val_ds, callbacks=[display_cb], epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uwsOAM_Wh-3",
        "outputId": "7aa03bc6-0e44-461b-89b9-21a7276155d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "203/203 [==============================] - ETA: 0s - loss: 1.6953target:     <that oswald was a good shot, somewhat better than or equal to  better than the average let us say.>\n",
            "prediction: <the the an the o t  aithe a the o o the te e h  the thee the athe an the ten e the te pe s of on s t the thnnthe tere o there t t the the the there oren t oront sare e ti s en o then  thiorente a the\n",
            "\n",
            "target:     <oswald said that this was not true. oswald denied that he had a rifle wrapped up in a blanket in the paine garage.>\n",
            "prediction: <the the an the o t  aithe a the o o the te e h  the thee the athe an the ten e the te pe s of on s t the thnnthe tere o there t t the the the there oren t oront sare e ti s en o then  thiorente a the\n",
            "\n",
            "target:     <the prisoners might be supervised and watched at every step, and made liable to punishment for a trifling breach of an irksome code of regulations,>\n",
            "prediction: <the the an the o t  aithe a the o o the te e h  the thee the athe an the ten e the te pe s of on s t the thnnthe tere o there t t the the the there oren t oront sare e ti s en o then  thiorente a the\n",
            "\n",
            "target:     <the route of the taxicab was retraced under the direction of whaley.>\n",
            "prediction: <the the an the o t  aithe a the on d an te e h  tho thee the athe an the ten e the te pe s of on s t the thnnthe tere o there t t the the the there oren t oront sare e ti s en o then  thiorente a the\n",
            "\n",
            "203/203 [==============================] - 195s 929ms/step - loss: 1.6953 - val_loss: 1.5076\n",
            "Epoch 2/50\n",
            "203/203 [==============================] - 180s 884ms/step - loss: 1.3864 - val_loss: 1.3179\n",
            "Epoch 3/50\n",
            "203/203 [==============================] - 181s 890ms/step - loss: 1.3213 - val_loss: 1.2931\n",
            "Epoch 4/50\n",
            "203/203 [==============================] - 182s 896ms/step - loss: 1.3067 - val_loss: 1.2824\n",
            "Epoch 5/50\n",
            "203/203 [==============================] - 180s 887ms/step - loss: 1.2963 - val_loss: 1.2705\n",
            "Epoch 6/50\n",
            "203/203 [==============================] - ETA: 0s - loss: 1.2754target:     <that oswald was a good shot, somewhat better than or equal to  better than the average let us say.>\n",
            "prediction: <the the was the the the the the the ould the the the the the the the the the the the the the the the the the the the the the the to wathe o the.>\n",
            "\n",
            "target:     <oswald said that this was not true. oswald denied that he had a rifle wrapped up in a blanket in the paine garage.>\n",
            "prediction: <the re the the the the wale the re the the re wand the the re the the re re the wale the re the roule re the re the re roswand.>\n",
            "\n",
            "target:     <the prisoners might be supervised and watched at every step, and made liable to punishment for a trifling breach of an irksome code of regulations,>\n",
            "prediction: <the the the the the the the the cof the the the the the the cof the the the the ware the the cofofore the the the pre the the the the the the the the cofore the ofoforererer kennedy.>\n",
            "\n",
            "target:     <the route of the taxicab was retraced under the direction of whaley.>\n",
            "prediction: <the re the the re the the the re the rere the the the the re the re the re the there the re the.>\n",
            "\n",
            "203/203 [==============================] - 188s 927ms/step - loss: 1.2754 - val_loss: 1.2447\n",
            "Epoch 7/50\n",
            "203/203 [==============================] - 180s 888ms/step - loss: 1.2326 - val_loss: 1.1861\n",
            "Epoch 8/50\n",
            "203/203 [==============================] - 188s 923ms/step - loss: 1.1463 - val_loss: 1.0696\n",
            "Epoch 9/50\n",
            "203/203 [==============================] - 182s 897ms/step - loss: 0.9938 - val_loss: 0.9157\n",
            "Epoch 10/50\n",
            "203/203 [==============================] - 181s 888ms/step - loss: 0.8579 - val_loss: 0.8168\n",
            "Epoch 11/50\n",
            "203/203 [==============================] - ETA: 0s - loss: 0.7759target:     <that oswald was a good shot, somewhat better than or equal to  better than the average let us say.>\n",
            "prediction: <the oswald bood than the as a good ther than the as awald to two ther than there than thered than ther the aver the.>\n",
            "\n",
            "target:     <oswald said that this was not true. oswald denied that he had a rifle wrapped up in a blanket in the paine garage.>\n",
            "prediction: <oswald sen not that the he had that the had that the had that the had that the had that the had that the had that there rive.>\n",
            "\n",
            "target:     <the prisoners might be supervised and watched at every step, and made liable to punishment for a trifling breach of an irksome code of regulations,>\n",
            "prediction: <the prison who reguld to prisons might be sup coling brifle to percts might be sup of and brifle to prisoners migulationshe con ce on corerer con ons.>\n",
            "\n",
            "target:     <the route of the taxicab was retraced under the direction of whaley.>\n",
            "prediction: <the rout was rection of was rection of was rection of was reaction of was rection of was rection of was rection of whe.>\n",
            "\n",
            "203/203 [==============================] - 185s 910ms/step - loss: 0.7759 - val_loss: 0.7668\n",
            "Epoch 12/50\n",
            "203/203 [==============================] - 179s 879ms/step - loss: 0.7232 - val_loss: 0.7335\n",
            "Epoch 13/50\n",
            "203/203 [==============================] - 181s 893ms/step - loss: 0.6852 - val_loss: 0.7059\n",
            "Epoch 14/50\n",
            "203/203 [==============================] - 180s 884ms/step - loss: 0.6599 - val_loss: 0.6895\n",
            "Epoch 15/50\n",
            "203/203 [==============================] - 178s 876ms/step - loss: 0.6396 - val_loss: 0.6747\n",
            "Epoch 16/50\n",
            "203/203 [==============================] - ETA: 0s - loss: 0.6172target:     <that oswald was a good shot, somewhat better than or equal to  better than the average let us say.>\n",
            "prediction: <that oswald thannal to oswald thannal thannal boright say.>\n",
            "\n",
            "target:     <oswald said that this was not true. oswald denied that he had a rifle wrapped up in a blanket in the paine garage.>\n",
            "prediction: <oswald said that this was not frain a blanked that this was not frate in a blanked that the he had riffold den not the had apathe.>\n",
            "\n",
            "target:     <the prisoners might be supervised and watched at every step, and made liable to punishment for a trifling breach of an irksome code of regulations,>\n",
            "prediction: <the prisoners might be steant for atrife reach of and make be stand might be stand might be stand might be stand might be seofof cofof corion tan ofof rin orion ofonerins.>\n",
            "\n",
            "target:     <the route of the taxicab was retraced under the direction of whaley.>\n",
            "prediction: <the rout a dirtion of was reation of was reation of was reatin of was reation of was reation of was reate.>\n",
            "\n",
            "203/203 [==============================] - 180s 888ms/step - loss: 0.6172 - val_loss: 0.6632\n",
            "Epoch 17/50\n",
            "203/203 [==============================] - 174s 855ms/step - loss: 0.5982 - val_loss: 0.6464\n",
            "Epoch 18/50\n",
            "203/203 [==============================] - 176s 864ms/step - loss: 0.5794 - val_loss: 0.6234\n",
            "Epoch 19/50\n",
            "203/203 [==============================] - 174s 857ms/step - loss: 0.5550 - val_loss: 0.6028\n",
            "Epoch 20/50\n",
            "203/203 [==============================] - 175s 860ms/step - loss: 0.5334 - val_loss: 0.5917\n",
            "Epoch 21/50\n",
            "203/203 [==============================] - ETA: 0s - loss: 0.5201target:     <that oswald was a good shot, somewhat better than or equal to  better than the average let us say.>\n",
            "prediction: <that oswald as a some oner eagll to assay gold as a say.>\n",
            "\n",
            "target:     <oswald said that this was not true. oswald denied that he had a rifle wrapped up in a blanket in the paine garage.>\n",
            "prediction: <oswald said that he had a radd that he had a rarradge, oswald denied that he had that he had a radge.>\n",
            "\n",
            "target:     <the prisoners might be supervised and watched at every step, and made liable to punishment for a trifling breach of an irksome code of regulations,>\n",
            "prediction: <the prisoners might be supervisoners might be supervisoners might be supervisoners might be supervise supervisoners might be suntantantes.>\n",
            "\n",
            "target:     <the route of the taxicab was retraced under the direction of whaley.>\n",
            "prediction: <the rout a traced under the drection of whaley.>\n",
            "\n",
            "203/203 [==============================] - 178s 875ms/step - loss: 0.5201 - val_loss: 0.5830\n",
            "Epoch 22/50\n",
            "203/203 [==============================] - 173s 852ms/step - loss: 0.5084 - val_loss: 0.5717\n",
            "Epoch 23/50\n",
            "203/203 [==============================] - 174s 855ms/step - loss: 0.4932 - val_loss: 0.5558\n",
            "Epoch 24/50\n",
            "203/203 [==============================] - 175s 862ms/step - loss: 0.4740 - val_loss: 0.5383\n",
            "Epoch 25/50\n",
            "203/203 [==============================] - 175s 862ms/step - loss: 0.4611 - val_loss: 0.5335\n",
            "Epoch 26/50\n",
            "203/203 [==============================] - ETA: 0s - loss: 0.4528target:     <that oswald was a good shot, somewhat better than or equal to  better than the average let us say.>\n",
            "prediction: <that oswald was good better than the average, some one better than the average, some one better than the average,>\n",
            "\n",
            "target:     <oswald said that this was not true. oswald denied that he had a rifle wrapped up in a blanket in the paine garage.>\n",
            "prediction: <oswald said that he had a rifle rat rifle rat rifle rat rifle rat den a blanket in the paine grage.>\n",
            "\n",
            "target:     <the prisoners might be supervised and watched at every step, and made liable to punishment for a trifling breach of an irksome code of regulations,>\n",
            "prediction: <the prisoners might be sepervised in watched enfor a trifling brised in watched enfor a trifling brisoners might be sepervised in watched ad livised in was.>\n",
            "\n",
            "target:     <the route of the taxicab was retraced under the direction of whaley.>\n",
            "prediction: <the route of the taxy cabe was reaced under the drection of whaley.>\n",
            "\n",
            "203/203 [==============================] - 178s 875ms/step - loss: 0.4528 - val_loss: 0.5271\n",
            "Epoch 27/50\n",
            "203/203 [==============================] - 175s 862ms/step - loss: 0.4464 - val_loss: 0.5221\n",
            "Epoch 28/50\n",
            "203/203 [==============================] - 175s 859ms/step - loss: 0.4398 - val_loss: 0.5200\n",
            "Epoch 29/50\n",
            "203/203 [==============================] - 175s 859ms/step - loss: 0.4343 - val_loss: 0.5198\n",
            "Epoch 30/50\n",
            "203/203 [==============================] - 176s 866ms/step - loss: 0.4306 - val_loss: 0.5145\n",
            "Epoch 31/50\n",
            "203/203 [==============================] - ETA: 0s - loss: 0.4253target:     <that oswald was a good shot, somewhat better than or equal to  better than the average let us say.>\n",
            "prediction: <that oswald was a goodsh wald was a goodshut say.>\n",
            "\n",
            "target:     <oswald said that this was not true. oswald denied that he had a rifle wrapped up in a blanket in the paine garage.>\n",
            "prediction: <oswald said that this was not chit in the paine groge. oswald said that he had a rifle rapt drifle rapt drifle rapt denied that he had a rifle rage.>\n",
            "\n",
            "target:     <the prisoners might be supervised and watched at every step, and made liable to punishment for a trifling breach of an irksome code of regulations,>\n",
            "prediction: <the prisoners might be supervised in washment for a trifling brised in washment for a trifling brised in be supervised and might be supervised in washment for cong pe.>\n",
            "\n",
            "target:     <the route of the taxicab was retraced under the direction of whaley.>\n",
            "prediction: <the rout of the taxied under the drection of whaley.>\n",
            "\n",
            "203/203 [==============================] - 179s 880ms/step - loss: 0.4253 - val_loss: 0.5200\n",
            "Epoch 32/50\n",
            "203/203 [==============================] - 176s 864ms/step - loss: 0.4238 - val_loss: 0.5497\n",
            "Epoch 33/50\n",
            "203/203 [==============================] - 175s 862ms/step - loss: 0.4269 - val_loss: 0.5055\n",
            "Epoch 34/50\n",
            "203/203 [==============================] - 174s 856ms/step - loss: 0.4128 - val_loss: 0.5072\n",
            "Epoch 35/50\n",
            "203/203 [==============================] - 177s 868ms/step - loss: 0.4086 - val_loss: 0.5087\n",
            "Epoch 36/50\n",
            "203/203 [==============================] - ETA: 0s - loss: 0.4087target:     <that oswald was a good shot, somewhat better than or equal to  better than the average let us say.>\n",
            "prediction: <that oswald was a good shot shot, some ond bedder than the average let a say.>\n",
            "\n",
            "target:     <oswald said that this was not true. oswald denied that he had a rifle wrapped up in a blanket in the paine garage.>\n",
            "prediction: <oswald said that this was not that he had rifle rater oswald said that he had rifle rater oswald said that he had rifle rage.>\n",
            "\n",
            "target:     <the prisoners might be supervised and watched at every step, and made liable to punishment for a trifling breach of an irksome code of regulations,>\n",
            "prediction: <the prisoners might be supervised in washment for a trifeling be supervised in washment for a trifling be supervised in washment for a trifling breach of an eare.>\n",
            "\n",
            "target:     <the route of the taxicab was retraced under the direction of whaley.>\n",
            "prediction: <the rout of the taxied under the direction of whaley.>\n",
            "\n",
            "203/203 [==============================] - 179s 880ms/step - loss: 0.4087 - val_loss: 0.5080\n",
            "Epoch 37/50\n",
            "203/203 [==============================] - 176s 865ms/step - loss: 0.4071 - val_loss: 0.5092\n",
            "Epoch 38/50\n",
            "203/203 [==============================] - 176s 866ms/step - loss: 0.4065 - val_loss: 0.5100\n",
            "Epoch 39/50\n",
            "203/203 [==============================] - 175s 859ms/step - loss: 0.4021 - val_loss: 0.5044\n",
            "Epoch 40/50\n",
            "203/203 [==============================] - 175s 862ms/step - loss: 0.4018 - val_loss: 0.5042\n",
            "Epoch 41/50\n",
            "203/203 [==============================] - ETA: 0s - loss: 0.3991target:     <that oswald was a good shot, somewhat better than or equal to  better than the average let us say.>\n",
            "prediction: <that oswald was a good shot, some one bed at ether than the average, some on bet etter than the average, some on bet it it it the average,>\n",
            "\n",
            "target:     <oswald said that this was not true. oswald denied that he had a rifle wrapped up in a blanket in the paine garage.>\n",
            "prediction: <oswald said that he had rifle rapd up enied that he had rifle rapd up in garage.>\n",
            "\n",
            "target:     <the prisoners might be supervised and watched at every step, and made liable to punishment for a trifling breach of an irksome code of regulations,>\n",
            "prediction: <the prisoners might be supervised in washment for a trifeling breach of an erksome coatevery gulations.>\n",
            "\n",
            "target:     <the route of the taxicab was retraced under the direction of whaley.>\n",
            "prediction: <the route of the taxiecabley.>\n",
            "\n",
            "203/203 [==============================] - 180s 885ms/step - loss: 0.3991 - val_loss: 0.5042\n",
            "Epoch 42/50\n",
            "203/203 [==============================] - 176s 864ms/step - loss: 0.3968 - val_loss: 0.5004\n",
            "Epoch 43/50\n",
            "203/203 [==============================] - 175s 860ms/step - loss: 0.3912 - val_loss: 0.5022\n",
            "Epoch 44/50\n",
            "203/203 [==============================] - 175s 859ms/step - loss: 0.3865 - val_loss: 0.5053\n",
            "Epoch 45/50\n",
            "203/203 [==============================] - 178s 876ms/step - loss: 0.3837 - val_loss: 0.5064\n",
            "Epoch 46/50\n",
            "203/203 [==============================] - ETA: 0s - loss: 0.3820target:     <that oswald was a good shot, somewhat better than or equal to  better than the average let us say.>\n",
            "prediction: <that oswald was a good shot bet it shot shot bet it shot bet it shot bet ith average le to better than the average le to better than the average l.>\n",
            "\n",
            "target:     <oswald said that this was not true. oswald denied that he had a rifle wrapped up in a blanket in the paine garage.>\n",
            "prediction: <oswald said that this was not the had arrage. oswald said that he had rifle rapped up en a blanket in the paine garage.>\n",
            "\n",
            "target:     <the prisoners might be supervised and watched at every step, and made liable to punishment for a trifling breach of an irksome code of regulations,>\n",
            "prediction: <the prisoners might be supervised in washment for a trife trife trife trife step, and bed liable to punishment for a trife trife trifling briest ins.>\n",
            "\n",
            "target:     <the route of the taxicab was retraced under the direction of whaley.>\n",
            "prediction: <the route of the taxieca ve whaley.>\n",
            "\n",
            "203/203 [==============================] - 179s 880ms/step - loss: 0.3820 - val_loss: 0.5040\n",
            "Epoch 47/50\n",
            "203/203 [==============================] - 175s 859ms/step - loss: 0.3800 - val_loss: 0.5026\n",
            "Epoch 48/50\n",
            "203/203 [==============================] - 174s 856ms/step - loss: 0.3795 - val_loss: 0.5059\n",
            "Epoch 49/50\n",
            "203/203 [==============================] - 173s 853ms/step - loss: 0.3764 - val_loss: 0.5064\n",
            "Epoch 50/50\n",
            "203/203 [==============================] - 175s 861ms/step - loss: 0.3750 - val_loss: 0.5078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('/')"
      ],
      "metadata": {
        "id": "na9dI_wJXWE9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WS1FXK5_9np7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}